{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Giriş\n",
        "Merhaba arkadaşlar Tensoflow öğrenme serüvenimizde ikinci çalışmadan merhaba, bu çalışmada Quickstart for experts kısmı üzerinde çalışacağız. Aslına bakarsanız ilk çalışmanın benzer adımlarına sahip olacak ama farklı veri seti hazırlamna aşamalarına ve model hazırlama aşamalarını bu bölümde göreceğiz."
      ],
      "metadata": {
        "id": "UVzVWx3nbHa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlaqJUDYVc9",
        "outputId": "0b1c77ce-9783-45da-e486-a6c377eff751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version:  2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri seti yükleme\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # Normalizasyon kısmı\n",
        "\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrsBwgJqcAag",
        "outputId": "158db11e-2605-47b4-f6a0-ab6327ec9931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizasyon kısımı** :  Bu kısımda x_train ve x_test içerisinde olan veriler 255.0 değerine gölünerek 0 ile 1 arasına indirgeniyor. Bu durum modelin daha hızlı ve kararlı öğrenmesini sağlıyor.\n",
        "\n",
        "**x_train = x_train[..., tf.newaxis].astype(\"float32\")** Bu kısımda 28x28 lik resim boyutunu tensor boyutuna çeviriyoruz 28x28x1. Bunu yapma nedenimiz CNN modellerinin tensor veri tipini kabult etmesinden dolayıdır."
      ],
      "metadata": {
        "id": "eWaVc31Sct49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaePNfphctJ_",
        "outputId": "eef46987-aa7e-4d1c-f0c3-17cafdf33af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "metadata": {
        "id": "rbIlI4JAd9TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**from_tensor_slices** : x_train ve y_train tensorlerinden bir dataset oluşturur.<br>\n",
        "**shuffle** : Verileri rastgele karıştırır.<br>\n",
        "**batch** : Verileri 32 öğeden oluşan mini-gruplar haline getirir.<br>"
      ],
      "metadata": {
        "id": "6QLgAPfNgOYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelin oluşturulması\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation = \"relu\") # Katman 1\n",
        "    self.flatten = Flatten() # Katman 2\n",
        "    self.d1 = Dense(128, activation = \"relu\") # katman 3\n",
        "    self.d2 = Dense(10) # katman 4\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "HNlnJx8Xejg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model oluşturma kısmı bir kısma bir önce çalışmalar ile aynı ama bazı yeniliklerde mevcur.<br>\n",
        "**Katman 1** : CNN model yapısından bir katmna 32 filtreye (feature maps) sahiptir, her biri 3x3 boyutunda ve ReLU aktivasyon fonksiyonunu kullanır.<br>\n",
        "\n",
        "Diğer katmanları ayır ayrı yazmayacağım bir önce çalışmamda katmanlardan bahsetmiştim.\n",
        "[Bir önceki çalışmam](Gelecek!)"
      ],
      "metadata": {
        "id": "JsuZH1rvj7gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True) # Kayıp(loss) değerlerinin hesaplanma işlemini gerçekleştirir.\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam optimizer fonksiyonu modeli eğitim adımından sonra güncelemek için kullanılır."
      ],
      "metadata": {
        "id": "Enx4ILnJjOJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name = \"train_loss\") # Bu eğitim esnasında \"loss\" eğitim kaybını hesaplayacak metriği oluşturur. train_loss olarak ifade edilecek.\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = \"train_accuracy\") # Accuracy değerinin hesaplanacağı kısım. train_accuracy olarak ifade edilecek\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name = \"test_loss\")\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = \"test_accuracy\")"
      ],
      "metadata": {
        "id": "Zgyf2fbUkuk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images, labels): # Fonksiyon\n",
        "  with tf.GradientTape() as tape: # Bu gradient hesaplama bağlamını başlatır. Bu bağlam içindeki tüm operasyonlar, gradientlerin hesaplanması kaydeder.\n",
        "    predictions = model(images, training = True) # modeli çağırarak görüntüler üzerinde tahminler yapar. training = True modelin eğitim modunda olduğunu belirtir.\n",
        "    loss = loss_object(labels, predictions) # tahminer ve gerçek etiket arasındaki kaybı hesaplar\n",
        "  gradients = tape.gradient(loss, model.trainable_variables) # Loss ve model.trainable_variable arasındaki gradientleri hesaplar\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # Gradientler ve model değişkenlerini optimize ediciye ileterek modelin parametrelerini günceller.\n",
        "\n",
        "  train_loss(loss) # eğitim kaybını günceler\n",
        "  train_accuracy(labels, predictions) # accuracy değerini günceller."
      ],
      "metadata": {
        "id": "kpisLwj0l6bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A-c_0GPjqzk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images, training = False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "metadata": {
        "id": "DtGdgAdhn_kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_state() # Her adım başında eğitim için metrikler sıfırlanır. Epochlar arası değerlerin ayrılmasını sağlar!\n",
        "  train_accuracy.reset_state()\n",
        "\n",
        "  test_loss.reset_state()\n",
        "  test_accuracy.reset_state()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels) # Eğitim aşaması\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels) # Test aşması\n",
        "\n",
        "  print(\n",
        "      f\"Epochs : {epoch + 1}, \"\n",
        "      f\"Loss : {train_loss.result():0.2f}, \"\n",
        "      f\"Accuracy : {train_accuracy.result() * 100:0.2f}, \"\n",
        "      f\"Test Loss: {test_loss.result():0.2f}, \"\n",
        "      f\"Test Accuracy: {test_accuracy.result() * 100:0.2f}\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGJRXkXHofU1",
        "outputId": "56c049f8-adf3-45a8-b17b-a820c74a6296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs : 1Loss : 0.13Accuracy : 96.07Test Loss: 0.05Test Accuracy: 98.23\n",
            "Epochs : 2Loss : 0.04Accuracy : 98.69Test Loss: 0.05Test Accuracy: 98.21\n",
            "Epochs : 3Loss : 0.02Accuracy : 99.30Test Loss: 0.05Test Accuracy: 98.34\n",
            "Epochs : 4Loss : 0.01Accuracy : 99.61Test Loss: 0.05Test Accuracy: 98.45\n",
            "Epochs : 5Loss : 0.01Accuracy : 99.69Test Loss: 0.05Test Accuracy: 98.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sonuç\n",
        "Quickstart for experts kısmınında sonuna geldik. Bu aşamada beginner seviyesine göre bazı adımları ayrı ayrı kodladık. Fikir vermek için erken diye düşünüyorum beginner seviyesindeki kod ile eğitim yapmak mı? yoksa experts bölümünkdeki kodlar ile eğitim yapma mı? İsteyen istediğini kullansın şimdilik. Tensorflow kütüphanesi tutorial kısmı üzerinde çalışmamızın başındayız ileride bakalım bizi ne gibi süprizler bekliyor hep birlikte göreceğiz!\n",
        "\n",
        "Aşağıdaki Linklerden beni takip edebilir ve yapacağım çalışmalardan haberdar olabilirsiniz!<br>\n",
        "[Linkedin](https://www.linkedin.com/in/ihsancenkiz/)<br>\n",
        "[Github](https://github.com/ihsncnkz)<br>\n",
        "[Kaggle](https://www.kaggle.com/ihsncnkz)"
      ],
      "metadata": {
        "id": "H7rlIqUx3YGN"
      }
    }
  ]
}